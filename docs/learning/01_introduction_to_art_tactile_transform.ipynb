{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Art Tactile Transform: Introduction & Overview\n",
    "\n",
    "Welcome to the Art Tactile Transform learning series! This notebook introduces you to the fascinating world of converting 2D images into 3D printable tactile models using AI.\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "By the end of this notebook, you will:\n",
    "- Understand what Art Tactile Transform does and why it's useful\n",
    "- Learn about the project architecture and components\n",
    "- Explore the technology stack and dependencies\n",
    "- Set up your development environment\n",
    "- Run your first transformation\n",
    "\n",
    "## üß© What is Art Tactile Transform?\n",
    "\n",
    "Art Tactile Transform is a Python application that converts flat 2D images into 3D printable tactile representations. It's particularly valuable for:\n",
    "\n",
    "- **Accessibility**: Creating tactile versions of artwork for visually impaired individuals\n",
    "- **Education**: Teaching concepts about depth, texture, and 3D modeling\n",
    "- **Art & Design**: Exploring new creative possibilities in mixed media\n",
    "- **3D Printing**: Generating interesting relief models for printing\n",
    "\n",
    "### The Process Flow\n",
    "```\n",
    "2D Image ‚Üí AI Depth Estimation ‚Üí Image Processing ‚Üí 3D Heightmap ‚Üí STL File ‚Üí 3D Print\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Project Architecture\n",
    "\n",
    "Let's explore the project structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T11:35:04.032581Z",
     "start_time": "2025-09-22T11:35:04.010884Z"
    }
   },
   "source": "## üèóÔ∏è Project Structure\n\n```\nart-tactile-transform/\n‚îú‚îÄ‚îÄ docs/\n‚îÇ   ‚îî‚îÄ‚îÄ learning/\n‚îÇ       ‚îú‚îÄ‚îÄ 01_introduction_to_art_tactile_transform.ipynb\n‚îÇ       ‚îú‚îÄ‚îÄ 02_depth_estimation_ai_concepts.ipynb\n‚îÇ       ‚îú‚îÄ‚îÄ 03_image_processing_techniques.ipynb\n‚îÇ       ‚îî‚îÄ‚îÄ 04_3d_modeling_stl_generation.ipynb\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îî‚îÄ‚îÄ art_tactile_transform/\n‚îÇ       ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ       ‚îî‚îÄ‚îÄ main.py\n‚îú‚îÄ‚îÄ tests/\n‚îÇ   ‚îú‚îÄ‚îÄ test_image_processing.py\n‚îÇ   ‚îú‚îÄ‚îÄ test_integration.py\n‚îÇ   ‚îú‚îÄ‚îÄ test_main.py\n‚îÇ   ‚îî‚îÄ‚îÄ test_stl_generation.py\n‚îú‚îÄ‚îÄ pyproject.toml\n‚îú‚îÄ‚îÄ poetry.lock\n‚îú‚îÄ‚îÄ README.md\n‚îî‚îÄ‚îÄ conftest.py\n```\n\n**üìÅ Key Components:**\n- `src/art_tactile_transform/` - Main application code\n- `tests/` - Test suite\n- `docs/learning/` - These educational notebooks\n- `pyproject.toml` - Poetry configuration\n- `.env` - Environment configuration"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Technology Stack\n",
    "\n",
    "Our project uses modern Python tools and AI technologies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T11:35:27.521714Z",
     "start_time": "2025-09-22T11:35:27.517084Z"
    }
   },
   "source": "## üõ†Ô∏è Technology Stack\n\n| Category | Technology |\n|----------|------------|\n| üêç Core Language | Python 3.13+ |\n| üì¶ Package Manager | Poetry |\n| ü§ñ AI Platform | Hugging Face Transformers |\n| üî¢ Numerical Computing | NumPy, SciPy |\n| üñºÔ∏è Image Processing | Pillow (PIL) |\n| üåê HTTP Requests | Requests |\n| ‚öôÔ∏è Configuration | python-dotenv |\n| üß™ Testing | pytest |\n| üìä 3D Output | STL format |\n\n**üß† AI Model Examples:**\n- Intel/dpt-large - Depth estimation transformer\n- Intel/dpt-hybrid-midas - Hybrid depth model\n- facebook/dpt-dinov2-base-kitti - Specialized depth model"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Quick Setup & First Run\n",
    "\n",
    "Let's set up the environment and run our first transformation:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T09:49:15.693824Z",
     "start_time": "2025-09-24T09:49:15.467974Z"
    }
   },
   "source": [
    "# Check if we can import our main module\n",
    "try:\n",
    "    from art_tactile_transform import generate_3d, query_hf_api\n",
    "    print(\"‚úÖ Successfully imported art_tactile_transform!\")\n",
    "    print(f\"üìç Module location: {generate_3d.__module__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import failed: {e}\")\n",
    "    print(\"üí° Make sure you've run: poetry install\")\n",
    "\n",
    "# Check environment setup\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "env_path = project_root / \".env\"\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(\"\\n‚öôÔ∏è Environment Configuration:\")\n",
    "    print(f\"MODEL_NAME: {os.getenv('MODEL_NAME', 'Not set')}\")\n",
    "    print(f\"IMAGE_PATH: {os.getenv('IMAGE_PATH', 'Not set')}\")\n",
    "    print(f\"OUTPUT_PATH: {os.getenv('OUTPUT_PATH', 'Not set')}\")\n",
    "    print(f\"RESOLUTION: {os.getenv('RESOLUTION', 'Not set')}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è .env file not found. Copy .env.example to .env and configure.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Import failed: No module named 'art_tactile_transform'\n",
      "üí° Make sure you've run: poetry install\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'project_root' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 15\u001B[39m\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mos\u001B[39;00m\n\u001B[32m     14\u001B[39m \u001B[38;5;66;03m# Load environment variables\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m env_path = \u001B[43mproject_root\u001B[49m / \u001B[33m\"\u001B[39m\u001B[33m.env\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m env_path.exists():\n\u001B[32m     17\u001B[39m     load_dotenv(env_path)\n",
      "\u001B[31mNameError\u001B[39m: name 'project_root' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Understanding the Core Process\n",
    "\n",
    "Let's examine each step of the transformation process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üé® Art Tactile Transform Process\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "process_steps = [\n",
    "    {\n",
    "        \"step\": \"1. Image Input\",\n",
    "        \"description\": \"Load and validate input image (PNG/JPG)\",\n",
    "        \"technical\": \"PIL Image.open() with format validation\"\n",
    "    },\n",
    "    {\n",
    "        \"step\": \"2. AI Depth Estimation\",\n",
    "        \"description\": \"Send image to Hugging Face depth model\",\n",
    "        \"technical\": \"HTTP POST to HF Inference API\"\n",
    "    },\n",
    "    {\n",
    "        \"step\": \"3. Image Processing\",\n",
    "        \"description\": \"Apply blur, clamping, borders, inversion\",\n",
    "        \"technical\": \"PIL filters + NumPy array operations\"\n",
    "    },\n",
    "    {\n",
    "        \"step\": \"4. Heightmap Generation\",\n",
    "        \"description\": \"Convert to normalized height values\",\n",
    "        \"technical\": \"Grayscale ‚Üí 0-1 float array\"\n",
    "    },\n",
    "    {\n",
    "        \"step\": \"5. Physical Scaling\",\n",
    "        \"description\": \"Apply real-world dimensions (mm)\",\n",
    "        \"technical\": \"Linear scaling with min/max heights\"\n",
    "    },\n",
    "    {\n",
    "        \"step\": \"6. STL Generation\",\n",
    "        \"description\": \"Create 3D mesh with proper normals\",\n",
    "        \"technical\": \"Triangle mesh with calculated normals\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, step_info in enumerate(process_steps, 1):\n",
    "    print(f\"\\n{step_info['step']}\")\n",
    "    print(f\"üìù {step_info['description']}\")\n",
    "    print(f\"‚öôÔ∏è {step_info['technical']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Code Deep Dive: Main Components\n",
    "\n",
    "Let's examine the key functions in our codebase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine the main functions\n",
    "import inspect\n",
    "from art_tactile_transform.main import (\n",
    "    query_hf_api, \n",
    "    process_image, \n",
    "    heightmap_to_stl, \n",
    "    calculate_normals,\n",
    "    generate_3d\n",
    ")\n",
    "\n",
    "functions_to_examine = [\n",
    "    (\"query_hf_api\", query_hf_api),\n",
    "    (\"process_image\", process_image),\n",
    "    (\"heightmap_to_stl\", heightmap_to_stl),\n",
    "    (\"calculate_normals\", calculate_normals),\n",
    "    (\"generate_3d\", generate_3d)\n",
    "]\n",
    "\n",
    "print(\"üî¨ Function Analysis\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "for func_name, func in functions_to_examine:\n",
    "    signature = inspect.signature(func)\n",
    "    docstring = inspect.getdoc(func)\n",
    "    \n",
    "    print(f\"\\nüìå {func_name}{signature}\")\n",
    "    print(f\"üìÑ {docstring or 'No docstring available'}\")\n",
    "    \n",
    "    # Show parameter types\n",
    "    params = []\n",
    "    for param_name, param in signature.parameters.items():\n",
    "        param_type = param.annotation if param.annotation != param.empty else \"Any\"\n",
    "        default = f\" = {param.default}\" if param.default != param.empty else \"\"\n",
    "        params.append(f\"{param_name}: {param_type}{default}\")\n",
    "    \n",
    "    if params:\n",
    "        print(f\"üîß Parameters: {', '.join(params[:3])}{'...' if len(params) > 3 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Configuration Deep Dive\n",
    "\n",
    "Understanding all the configuration options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Configuration Parameters\")\n",
    "print(\"=\"*35)\n",
    "\n",
    "config_params = {\n",
    "    \"üéØ Core Settings\": {\n",
    "        \"MODEL_NAME\": \"HuggingFace depth estimation model\",\n",
    "        \"IMAGE_PATH\": \"Input image file path\",\n",
    "        \"OUTPUT_PATH\": \"Output STL file path\",\n",
    "        \"RESOLUTION\": \"Target processing resolution (pixels)\",\n",
    "        \"HF_API_TOKEN\": \"Optional HuggingFace API token\"\n",
    "    },\n",
    "    \"üìê Physical Dimensions\": {\n",
    "        \"MIN_HEIGHT_MM\": \"Minimum tactile height (millimeters)\",\n",
    "        \"MAX_HEIGHT_MM\": \"Maximum tactile height (millimeters)\",\n",
    "        \"BASE_THICKNESS_MM\": \"Base plate thickness (millimeters)\",\n",
    "        \"PIXEL_SCALE_MM\": \"Scale factor: mm per pixel\"\n",
    "    },\n",
    "    \"üé® Image Processing\": {\n",
    "        \"INVERT_HEIGHTS\": \"Invert depth mapping (dark=high)\",\n",
    "        \"GAUSSIAN_BLUR_RADIUS\": \"Blur radius in pixels (smoothing)\",\n",
    "        \"CLAMP_MIN/MAX\": \"Contrast clamping (0-255 range)\",\n",
    "        \"BORDER_PIXELS\": \"Add border around image\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for category, params in config_params.items():\n",
    "    print(f\"\\n{category}\")\n",
    "    for param, description in params.items():\n",
    "        print(f\"  ‚Ä¢ {param:<20} - {description}\")\n",
    "\n",
    "print(\"\\nüí° Pro Tips:\")\n",
    "print(\"‚Ä¢ Start with RESOLUTION=64 for fast testing\")\n",
    "print(\"‚Ä¢ Use GAUSSIAN_BLUR_RADIUS=2-5 for smoother surfaces\")\n",
    "print(\"‚Ä¢ Adjust MIN/MAX_HEIGHT_MM based on your 3D printer capabilities\")\n",
    "print(\"‚Ä¢ PIXEL_SCALE_MM determines final model size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Practice Exercise 1: Environment Setup\n",
    "\n",
    "Complete the following tasks to ensure your environment is properly configured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Exercise 1: Environment Validation\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Task 1: Check Poetry installation\n",
    "import subprocess\n",
    "try:\n",
    "    result = subprocess.run([\"poetry\", \"--version\"], capture_output=True, text=True)\n",
    "    print(f\"‚úÖ Poetry version: {result.stdout.strip()}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Poetry not found. Install with: pip install poetry\")\n",
    "\n",
    "# Task 2: Validate required imports\n",
    "required_packages = [\n",
    "    (\"numpy\", \"np\"),\n",
    "    (\"PIL\", \"Image\"),\n",
    "    (\"requests\", \"requests\"),\n",
    "    (\"dotenv\", \"load_dotenv\"),\n",
    "    (\"scipy\", \"scipy\")\n",
    "]\n",
    "\n",
    "print(\"\\nüì¶ Package Validation:\")\n",
    "for package, import_name in required_packages:\n",
    "    try:\n",
    "        exec(f\"import {import_name}\")\n",
    "        print(f\"‚úÖ {package} - Available\")\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå {package} - Missing (run: poetry install)\")\n",
    "\n",
    "# Task 3: Check .env configuration\n",
    "print(\"\\n‚öôÔ∏è Configuration Check:\")\n",
    "required_env_vars = [\"MODEL_NAME\", \"IMAGE_PATH\", \"OUTPUT_PATH\"]\n",
    "missing_vars = []\n",
    "\n",
    "for var in required_env_vars:\n",
    "    value = os.getenv(var)\n",
    "    if value:\n",
    "        print(f\"‚úÖ {var} = {value}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {var} - Not set\")\n",
    "        missing_vars.append(var)\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"\\nüí° Please set these variables in your .env file: {', '.join(missing_vars)}\")\n",
    "else:\n",
    "    print(\"\\nüéâ All configuration looks good!\")\n",
    "\n",
    "print(\"\\nüìù Your Tasks:\")\n",
    "print(\"1. Ensure Poetry is installed and working\")\n",
    "print(\"2. Run 'poetry install' to install all dependencies\")\n",
    "print(\"3. Copy .env.example to .env and configure paths\")\n",
    "print(\"4. Choose a small test image for your first transformation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Practice Exercise 2: First Transformation\n",
    "\n",
    "Let's create a simple test image and transform it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "print(\"üöÄ Exercise 2: Create Your First Tactile Model\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create a simple test pattern\n",
    "def create_test_image(size=(128, 128)):\n",
    "    \"\"\"Create a test image with interesting depth patterns.\"\"\"\n",
    "    img = Image.new('RGB', size, 'white')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # Draw concentric circles with varying intensity\n",
    "    center_x, center_y = size[0] // 2, size[1] // 2\n",
    "    \n",
    "    for radius in range(10, min(size) // 2, 15):\n",
    "        intensity = 255 - (radius * 3)\n",
    "        if intensity < 0:\n",
    "            intensity = 0\n",
    "        color = (intensity, intensity, intensity)\n",
    "        \n",
    "        draw.ellipse([\n",
    "            center_x - radius, center_y - radius,\n",
    "            center_x + radius, center_y + radius\n",
    "        ], fill=color)\n",
    "    \n",
    "    # Add some rectangular features\n",
    "    draw.rectangle([10, 10, 30, 30], fill=(128, 128, 128))\n",
    "    draw.rectangle([size[0]-30, 10, size[0]-10, 30], fill=(64, 64, 64))\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Create and save test image\n",
    "test_img = create_test_image()\n",
    "test_path = project_root / \"test_input.png\"\n",
    "test_img.save(test_path)\n",
    "\n",
    "print(f\"‚úÖ Created test image: {test_path}\")\n",
    "print(f\"üìè Image size: {test_img.size}\")\n",
    "print(f\"üé® Mode: {test_img.mode}\")\n",
    "\n",
    "# Display what the test image looks like (if in a proper Jupyter environment)\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(test_img)\n",
    "    plt.title(\"Test Image - Concentric Circles Pattern\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(\"üìä Image displayed above\")\n",
    "except ImportError:\n",
    "    print(\"üìä Install matplotlib to see image visualization\")\n",
    "\n",
    "print(\"\\nüìù Next Steps:\")\n",
    "print(\"1. Set IMAGE_PATH in .env to point to test_input.png\")\n",
    "print(\"2. Set OUTPUT_PATH to your desired STL location\")\n",
    "print(\"3. Run: poetry run art-tactile-transform\")\n",
    "print(\"4. Check the generated STL file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Key Concepts Summary\n",
    "\n",
    "After completing this introduction, you should understand:\n",
    "\n",
    "### ‚úÖ Core Concepts\n",
    "- **Depth Estimation**: AI models predict depth from 2D images\n",
    "- **Heightmaps**: Grayscale images representing 3D surface heights\n",
    "- **STL Format**: Standard file format for 3D printing\n",
    "- **Physical Scaling**: Converting pixels to real-world dimensions\n",
    "\n",
    "### ‚úÖ Technical Skills\n",
    "- Poetry project management\n",
    "- Environment configuration with .env files\n",
    "- Python package structure and imports\n",
    "- Basic image processing concepts\n",
    "\n",
    "### ‚úÖ Project Architecture\n",
    "- Modular design with separation of concerns\n",
    "- Configuration-driven behavior\n",
    "- Comprehensive testing approach\n",
    "- Modern Python development practices\n",
    "\n",
    "## üéØ Next Steps\n",
    "\n",
    "Continue your learning journey with:\n",
    "\n",
    "1. **02_depth_estimation_ai_concepts.ipynb** - Deep dive into AI depth estimation\n",
    "2. **03_image_processing_techniques.ipynb** - Advanced image processing\n",
    "3. **04_3d_modeling_stl_generation.ipynb** - 3D mesh creation and STL format\n",
    "4. **05_hands_on_exercises.ipynb** - Practical coding exercises\n",
    "5. **06_advanced_challenges.ipynb** - Enhancement projects\n",
    "\n",
    "Each notebook builds on the previous one, so follow the sequence for the best learning experience!\n",
    "\n",
    "---\n",
    "*Happy learning! üöÄ*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
