{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing Techniques for Tactile Enhancement\n",
    "\n",
    "Welcome to the third notebook in our Art Tactile Transform series! This notebook focuses on the image processing pipeline that transforms raw depth maps into optimized tactile representations.\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "By the end of this notebook, you will:\n",
    "- Understand each step in the image processing pipeline\n",
    "- Learn how different filters affect tactile quality\n",
    "- Master the configuration parameters for optimal results\n",
    "- Implement custom image processing workflows\n",
    "- Troubleshoot common image processing issues\n",
    "\n",
    "## üñºÔ∏è The Image Processing Pipeline\n",
    "\n",
    "Our application transforms depth maps through several processing stages to create optimal tactile representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter, ImageDraw\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project to Python path\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "print(\"üñºÔ∏è Image Processing Pipeline Overview\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "pipeline_stages = [\n",
    "    {\n",
    "        \"stage\": \"1. Input Validation\",\n",
    "        \"purpose\": \"Ensure image is in correct format\",\n",
    "        \"operations\": [\"Format check\", \"Size validation\", \"Color mode conversion\"]\n",
    "    },\n",
    "    {\n",
    "        \"stage\": \"2. Grayscale Conversion\",\n",
    "        \"purpose\": \"Convert to single-channel depth representation\",\n",
    "        \"operations\": [\"RGB to grayscale\", \"Preserve depth information\"]\n",
    "    },\n",
    "    {\n",
    "        \"stage\": \"3. Border Addition\",\n",
    "        \"purpose\": \"Add consistent edges for 3D printing\",\n",
    "        \"operations\": [\"Padding with border pixels\", \"Edge consistency\"]\n",
    "    },\n",
    "    {\n",
    "        \"stage\": \"4. Gaussian Blur\",\n",
    "        \"purpose\": \"Smooth surface for better tactile feel\",\n",
    "        \"operations\": [\"Noise reduction\", \"Surface smoothing\", \"Feature preservation\"]\n",
    "    },\n",
    "    {\n",
    "        \"stage\": \"5. Value Clamping\",\n",
    "        \"purpose\": \"Control contrast and dynamic range\",\n",
    "        \"operations\": [\"Min/max limiting\", \"Contrast enhancement\"]\n",
    "    },\n",
    "    {\n",
    "        \"stage\": \"6. Normalization\",\n",
    "        \"purpose\": \"Scale to 0-1 range for processing\",\n",
    "        \"operations\": [\"Linear scaling\", \"Range mapping\"]\n",
    "    },\n",
    "    {\n",
    "        \"stage\": \"7. Height Inversion\",\n",
    "        \"purpose\": \"Optionally invert depth interpretation\",\n",
    "        \"operations\": [\"Conditional inversion\", \"Dark=high option\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "for stage_info in pipeline_stages:\n",
    "    print(f\"\\nüìã {stage_info['stage']}\")\n",
    "    print(f\"   üéØ Purpose: {stage_info['purpose']}\")\n",
    "    print(f\"   ‚öôÔ∏è Operations: {', '.join(stage_info['operations'])}\")\n",
    "\n",
    "print(\"\\nüí° Key Insight:\")\n",
    "print(\"Each stage serves both image quality and tactile usability goals.\")\n",
    "print(\"The pipeline optimizes for touch perception, not just visual appeal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Deep Dive: Process Image Function\n",
    "\n",
    "Let's examine our main image processing function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art_tactile_transform.main import process_image\n",
    "import inspect\n",
    "\n",
    "print(\"üîç Process Image Function Analysis\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Show function signature\n",
    "signature = inspect.signature(process_image)\n",
    "print(f\"üìã Function Signature:\")\n",
    "print(f\"process_image{signature}\")\n",
    "\n",
    "# Show function source\n",
    "print(\"\\nüìù Function Implementation:\")\n",
    "print(inspect.getsource(process_image))\n",
    "\n",
    "print(\"\\nüîß Parameter Details:\")\n",
    "params = {\n",
    "    \"gaussian_blur_radius\": \"Smoothing filter radius (0 = disabled)\",\n",
    "    \"clamp_min/max\": \"Contrast control range (0-255)\",\n",
    "    \"border_pixels\": \"Edge padding size in pixels\",\n",
    "    \"invert_heights\": \"Reverse depth interpretation (bool)\"\n",
    "}\n",
    "\n",
    "for param, description in params.items():\n",
    "    print(f\"‚Ä¢ {param:<20}: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Interactive Processing Demonstration\n",
    "\n",
    "Let's create a demonstration of each processing stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_demo_depth_map(size=(128, 128)):\n",
    "    \"\"\"Create a synthetic depth map for demonstration.\"\"\"\n",
    "    img = Image.new('RGB', size, 'white')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # Create interesting depth features\n",
    "    center_x, center_y = size[0] // 2, size[1] // 2\n",
    "    \n",
    "    # Background gradient\n",
    "    for y in range(size[1]):\n",
    "        intensity = int(255 * (1 - y / size[1]))\n",
    "        draw.line([(0, y), (size[0], y)], fill=(intensity, intensity, intensity))\n",
    "    \n",
    "    # Add some geometric shapes with different depths\n",
    "    draw.ellipse([20, 20, 60, 60], fill=(200, 200, 200))  # Light circle\n",
    "    draw.rectangle([80, 30, 110, 70], fill=(100, 100, 100))  # Dark rectangle\n",
    "    draw.ellipse([center_x-15, center_y-15, center_x+15, center_y+15], fill=(50, 50, 50))  # Dark center\n",
    "    \n",
    "    # Add some noise\n",
    "    for _ in range(20):\n",
    "        x, y = np.random.randint(0, size[0]), np.random.randint(0, size[1])\n",
    "        intensity = np.random.randint(0, 255)\n",
    "        draw.point((x, y), fill=(intensity, intensity, intensity))\n",
    "    \n",
    "    return img\n",
    "\n",
    "def demonstrate_processing_stages(input_image):\n",
    "    \"\"\"Show the effect of each processing stage.\"\"\"\n",
    "    stages = {}\n",
    "    \n",
    "    # Stage 1: Original\n",
    "    stages['Original'] = input_image.copy()\n",
    "    \n",
    "    # Stage 2: Grayscale conversion\n",
    "    gray_img = input_image.convert('L')\n",
    "    stages['Grayscale'] = gray_img\n",
    "    \n",
    "    # Stage 3: With border\n",
    "    border_img = process_image(gray_img, border_pixels=5)\n",
    "    stages['With Border'] = border_img\n",
    "    \n",
    "    # Stage 4: Gaussian blur\n",
    "    blur_img = process_image(gray_img, gaussian_blur_radius=3)\n",
    "    stages['Blurred'] = blur_img\n",
    "    \n",
    "    # Stage 5: Clamped\n",
    "    clamp_img = process_image(gray_img, clamp_min=50, clamp_max=200)\n",
    "    stages['Clamped'] = clamp_img\n",
    "    \n",
    "    # Stage 6: Inverted\n",
    "    invert_img = process_image(gray_img, invert_heights=True)\n",
    "    stages['Inverted'] = invert_img\n",
    "    \n",
    "    return stages\n",
    "\n",
    "# Create demo image\n",
    "demo_img = create_demo_depth_map()\n",
    "processing_stages = demonstrate_processing_stages(demo_img)\n",
    "\n",
    "print(\"üé® Processing Stage Demonstration\")\n",
    "print(\"=\"*35)\n",
    "print(f\"‚úÖ Created demo depth map with {len(processing_stages)} processing variations\")\n",
    "\n",
    "# Display the stages if matplotlib is available\n",
    "try:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (stage_name, img) in enumerate(processing_stages.items()):\n",
    "        if i < len(axes):\n",
    "            # Convert PIL to numpy for display\n",
    "            if img.mode == 'RGB':\n",
    "                img_array = np.array(img)\n",
    "            else:\n",
    "                img_array = np.array(img)\n",
    "                if len(img_array.shape) == 2:\n",
    "                    # For grayscale images\n",
    "                    pass\n",
    "            \n",
    "            axes[i].imshow(img_array, cmap='gray' if img.mode == 'L' else None)\n",
    "            axes[i].set_title(stage_name)\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for i in range(len(processing_stages), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"Image Processing Stages Comparison\", y=1.02)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üìä Stage comparison visualized above\")\n",
    "except ImportError:\n",
    "    print(\"üìä Install matplotlib to see stage visualizations\")\n",
    "\n",
    "print(\"\\nüîç Observe the differences:\")\n",
    "print(\"‚Ä¢ Border adds consistent edges\")\n",
    "print(\"‚Ä¢ Blur smooths out noise and sharp edges\")\n",
    "print(\"‚Ä¢ Clamping adjusts contrast range\")\n",
    "print(\"‚Ä¢ Inversion changes depth interpretation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Parameter Effects Analysis\n",
    "\n",
    "Let's explore how different parameter values affect the final result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_parameter_effects(base_image):\n",
    "    \"\"\"Analyze the effect of different parameter values.\"\"\"\n",
    "    \n",
    "    print(\"üîß Parameter Effects Analysis\")\n",
    "    print(\"=\"*35)\n",
    "    \n",
    "    # Convert to grayscale for processing\n",
    "    if base_image.mode != 'L':\n",
    "        base_image = base_image.convert('L')\n",
    "    \n",
    "    # Test Gaussian blur radius\n",
    "    print(\"\\nüìä Gaussian Blur Radius Effects:\")\n",
    "    blur_tests = [0, 1, 3, 5, 10]\n",
    "    blur_results = {}\n",
    "    \n",
    "    for radius in blur_tests:\n",
    "        result = process_image(base_image, gaussian_blur_radius=radius)\n",
    "        blur_results[f\"Radius {radius}\"] = result\n",
    "        \n",
    "        # Calculate some statistics\n",
    "        img_array = np.array(result)\n",
    "        mean_val = np.mean(img_array)\n",
    "        std_val = np.std(img_array)\n",
    "        \n",
    "        print(f\"   Radius {radius:2d}: Mean={mean_val:6.2f}, Std={std_val:6.2f}\")\n",
    "    \n",
    "    # Test clamping effects\n",
    "    print(\"\\nüìä Clamping Range Effects:\")\n",
    "    clamp_tests = [\n",
    "        (0, 255),    # No clamping\n",
    "        (50, 200),   # Moderate clamping\n",
    "        (100, 150),  # Heavy clamping\n",
    "        (0, 128),    # Lower half only\n",
    "        (128, 255)   # Upper half only\n",
    "    ]\n",
    "    \n",
    "    clamp_results = {}\n",
    "    for min_val, max_val in clamp_tests:\n",
    "        result = process_image(base_image, clamp_min=min_val, clamp_max=max_val)\n",
    "        clamp_results[f\"Clamp {min_val}-{max_val}\"] = result\n",
    "        \n",
    "        img_array = np.array(result)\n",
    "        actual_min, actual_max = np.min(img_array), np.max(img_array)\n",
    "        dynamic_range = actual_max - actual_min\n",
    "        \n",
    "        print(f\"   {min_val:3d}-{max_val:3d}: Range={actual_min:5.1f}-{actual_max:5.1f}, Dynamic={dynamic_range:5.1f}\")\n",
    "    \n",
    "    # Test border effects\n",
    "    print(\"\\nüìä Border Size Effects:\")\n",
    "    border_tests = [0, 2, 5, 10, 20]\n",
    "    border_results = {}\n",
    "    \n",
    "    for border_size in border_tests:\n",
    "        result = process_image(base_image, border_pixels=border_size)\n",
    "        border_results[f\"Border {border_size}\"] = result\n",
    "        \n",
    "        original_size = base_image.size\n",
    "        new_size = result.size\n",
    "        size_increase = (new_size[0] - original_size[0], new_size[1] - original_size[1])\n",
    "        \n",
    "        print(f\"   Border {border_size:2d}: Size {original_size} ‚Üí {new_size} (+{size_increase})\")\n",
    "    \n",
    "    return {\n",
    "        'blur': blur_results,\n",
    "        'clamp': clamp_results,\n",
    "        'border': border_results\n",
    "    }\n",
    "\n",
    "# Analyze parameter effects\n",
    "parameter_results = analyze_parameter_effects(demo_img)\n",
    "\n",
    "print(\"\\nüí° Parameter Selection Guidelines:\")\n",
    "print(\"‚Ä¢ Blur Radius: 2-5 for smooth tactile surfaces, 0 for sharp details\")\n",
    "print(\"‚Ä¢ Clamping: Narrow range for high contrast, wide for subtle variations\")\n",
    "print(\"‚Ä¢ Border: 5-10 pixels for stable 3D printing edges\")\n",
    "print(\"‚Ä¢ Inversion: Use when dark areas should be raised (artistic preference)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Understanding Tactile Perception\n",
    "\n",
    "The image processing choices directly affect how the final tactile model feels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß† Tactile Perception & Image Processing\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "tactile_considerations = {\n",
    "    \"Surface Smoothness\": {\n",
    "        \"goal\": \"Comfortable touch experience\",\n",
    "        \"processing\": \"Gaussian blur reduces sharp edges\",\n",
    "        \"parameter\": \"gaussian_blur_radius=2-5\",\n",
    "        \"trade_off\": \"Smoothness vs detail preservation\"\n",
    "    },\n",
    "    \"Height Variation\": {\n",
    "        \"goal\": \"Distinguishable tactile features\",\n",
    "        \"processing\": \"Clamping controls contrast\",\n",
    "        \"parameter\": \"clamp_min/max for dynamic range\",\n",
    "        \"trade_off\": \"Contrast vs gradual transitions\"\n",
    "    },\n",
    "    \"Edge Definition\": {\n",
    "        \"goal\": \"Clear tactile boundaries\",\n",
    "        \"processing\": \"Border pixels provide consistent edges\",\n",
    "        \"parameter\": \"border_pixels=5-10\",\n",
    "        \"trade_off\": \"Edge clarity vs size increase\"\n",
    "    },\n",
    "    \"Depth Interpretation\": {\n",
    "        \"goal\": \"Intuitive height mapping\",\n",
    "        \"processing\": \"Inversion changes dark=high vs light=high\",\n",
    "        \"parameter\": \"invert_heights boolean\",\n",
    "        \"trade_off\": \"Artistic choice vs conventional mapping\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for aspect, details in tactile_considerations.items():\n",
    "    print(f\"\\nüëÜ {aspect}\")\n",
    "    for key, value in details.items():\n",
    "        print(f\"   {key.replace('_', ' ').title():<12}: {value}\")\n",
    "\n",
    "print(\"\\nüî¨ Human Touch Sensitivity:\")\n",
    "touch_facts = [\n",
    "    \"Fingertips can detect height differences as small as 10 micrometers\",\n",
    "    \"Optimal tactile features are 0.5-3mm in height variation\",\n",
    "    \"Sharp edges can be uncomfortable and may break during printing\",\n",
    "    \"Gradual slopes are easier to interpret than sudden height changes\",\n",
    "    \"Pattern regularity helps with tactile interpretation\"\n",
    "]\n",
    "\n",
    "for fact in touch_facts:\n",
    "    print(f\"‚Ä¢ {fact}\")\n",
    "\n",
    "print(\"\\nüéØ Optimization Strategy:\")\n",
    "print(\"1. Start with moderate blur (radius=3) for smooth surfaces\")\n",
    "print(\"2. Use clamping to ensure adequate height variation\")\n",
    "print(\"3. Add borders for stable printing and handling\")\n",
    "print(\"4. Test both normal and inverted height interpretations\")\n",
    "print(\"5. Consider the intended use case (art, education, accessibility)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Advanced Processing Techniques\n",
    "\n",
    "Let's explore some advanced image processing concepts that could enhance our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_advanced_techniques(base_image):\n",
    "    \"\"\"Demonstrate advanced image processing techniques.\"\"\"\n",
    "    \n",
    "    print(\"üîç Advanced Processing Techniques\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    if base_image.mode != 'L':\n",
    "        base_image = base_image.convert('L')\n",
    "    \n",
    "    img_array = np.array(base_image).astype(float)\n",
    "    advanced_results = {}\n",
    "    \n",
    "    # 1. Histogram Equalization\n",
    "    def histogram_equalization(img_array):\n",
    "        \"\"\"Apply histogram equalization for better contrast.\"\"\"\n",
    "        hist, bins = np.histogram(img_array.flatten(), 256, [0, 256])\n",
    "        cdf = hist.cumsum()\n",
    "        cdf_normalized = cdf * hist.max() / cdf.max()\n",
    "        \n",
    "        # Create mapping\n",
    "        cdf_m = np.ma.masked_equal(cdf, 0)\n",
    "        cdf_m = (cdf_m - cdf_m.min()) * 255 / (cdf_m.max() - cdf_m.min())\n",
    "        cdf = np.ma.filled(cdf_m, 0).astype('uint8')\n",
    "        \n",
    "        # Apply mapping\n",
    "        equalized = cdf[img_array.astype('uint8')]\n",
    "        return equalized\n",
    "    \n",
    "    hist_eq = histogram_equalization(img_array)\n",
    "    advanced_results['Histogram Equalized'] = Image.fromarray(hist_eq.astype('uint8'), mode='L')\n",
    "    \n",
    "    # 2. Adaptive Gaussian Filter\n",
    "    def adaptive_gaussian(img_array):\n",
    "        \"\"\"Apply variable blur based on local image properties.\"\"\"\n",
    "        # Calculate local variance\n",
    "        from scipy.ndimage import uniform_filter\n",
    "        local_mean = uniform_filter(img_array, size=5)\n",
    "        local_var = uniform_filter(img_array**2, size=5) - local_mean**2\n",
    "        \n",
    "        # Normalize variance to 0-1\n",
    "        var_norm = (local_var - local_var.min()) / (local_var.max() - local_var.min() + 1e-8)\n",
    "        \n",
    "        # Apply variable blur: more blur where variance is low\n",
    "        result = img_array.copy()\n",
    "        for sigma in [1, 2, 3]:\n",
    "            blurred = gaussian_filter(img_array, sigma=sigma)\n",
    "            mask = var_norm < (sigma / 3.0)\n",
    "            result[mask] = blurred[mask]\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    adaptive_blur = adaptive_gaussian(img_array)\n",
    "    advanced_results['Adaptive Blur'] = Image.fromarray(adaptive_blur.astype('uint8'), mode='L')\n",
    "    \n",
    "    # 3. Edge-Preserving Smoothing (simplified bilateral filter)\n",
    "    def simple_edge_preserving(img_array, sigma_spatial=2, sigma_intensity=20):\n",
    "        \"\"\"Simple edge-preserving smoothing.\"\"\"\n",
    "        result = img_array.copy()\n",
    "        h, w = img_array.shape\n",
    "        \n",
    "        for i in range(1, h-1):\n",
    "            for j in range(1, w-1):\n",
    "                center_val = img_array[i, j]\n",
    "                weights = []\n",
    "                values = []\n",
    "                \n",
    "                for di in [-1, 0, 1]:\n",
    "                    for dj in [-1, 0, 1]:\n",
    "                        neighbor_val = img_array[i+di, j+dj]\n",
    "                        \n",
    "                        # Spatial weight (distance)\n",
    "                        spatial_weight = np.exp(-(di**2 + dj**2) / (2 * sigma_spatial**2))\n",
    "                        \n",
    "                        # Intensity weight (similarity)\n",
    "                        intensity_weight = np.exp(-((center_val - neighbor_val)**2) / (2 * sigma_intensity**2))\n",
    "                        \n",
    "                        total_weight = spatial_weight * intensity_weight\n",
    "                        weights.append(total_weight)\n",
    "                        values.append(neighbor_val)\n",
    "                \n",
    "                # Weighted average\n",
    "                weights = np.array(weights)\n",
    "                values = np.array(values)\n",
    "                result[i, j] = np.sum(weights * values) / np.sum(weights)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # Apply to a smaller region for demonstration (full image would be slow)\n",
    "    small_region = img_array[20:60, 20:60]\n",
    "    edge_preserving = simple_edge_preserving(small_region)\n",
    "    \n",
    "    # Create full-size result for display\n",
    "    edge_result = img_array.copy()\n",
    "    edge_result[20:60, 20:60] = edge_preserving\n",
    "    advanced_results['Edge Preserving'] = Image.fromarray(edge_result.astype('uint8'), mode='L')\n",
    "    \n",
    "    # 4. Multi-scale Processing\n",
    "    def multiscale_enhancement(img_array):\n",
    "        \"\"\"Combine multiple scales for enhanced detail.\"\"\"\n",
    "        # Create multiple scales\n",
    "        scale1 = gaussian_filter(img_array, sigma=1)  # Fine details\n",
    "        scale2 = gaussian_filter(img_array, sigma=3)  # Medium features\n",
    "        scale3 = gaussian_filter(img_array, sigma=6)  # Large structures\n",
    "        \n",
    "        # Combine scales with different weights\n",
    "        result = 0.5 * scale1 + 0.3 * scale2 + 0.2 * scale3\n",
    "        \n",
    "        # Normalize to 0-255 range\n",
    "        result = (result - result.min()) / (result.max() - result.min()) * 255\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    multiscale = multiscale_enhancement(img_array)\n",
    "    advanced_results['Multiscale'] = Image.fromarray(multiscale.astype('uint8'), mode='L')\n",
    "    \n",
    "    return advanced_results\n",
    "\n",
    "# Demonstrate advanced techniques\n",
    "advanced_results = demonstrate_advanced_techniques(demo_img)\n",
    "\n",
    "print(f\"‚úÖ Generated {len(advanced_results)} advanced processing examples\")\n",
    "\n",
    "# Display advanced results\n",
    "try:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (technique_name, img) in enumerate(advanced_results.items()):\n",
    "        if i < len(axes):\n",
    "            axes[i].imshow(np.array(img), cmap='gray')\n",
    "            axes[i].set_title(technique_name)\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"Advanced Image Processing Techniques\", y=1.02)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üìä Advanced techniques visualized above\")\n",
    "except ImportError:\n",
    "    print(\"üìä Install matplotlib to see advanced technique visualizations\")\n",
    "\n",
    "print(\"\\nüéØ When to Use Advanced Techniques:\")\n",
    "print(\"‚Ä¢ Histogram Equalization: Low contrast images\")\n",
    "print(\"‚Ä¢ Adaptive Blur: Images with varying detail levels\")\n",
    "print(\"‚Ä¢ Edge Preserving: Maintain sharp boundaries while smoothing\")\n",
    "print(\"‚Ä¢ Multiscale: Combine fine details with large structures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Custom Processing Pipeline Builder\n",
    "\n",
    "Let's create a flexible pipeline for custom image processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TactileProcessingPipeline:\n",
    "    \"\"\"Flexible image processing pipeline for tactile enhancement.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.steps = []\n",
    "        self.results = {}\n",
    "    \n",
    "    def add_step(self, name, function, **kwargs):\n",
    "        \"\"\"Add a processing step to the pipeline.\"\"\"\n",
    "        self.steps.append({\n",
    "            'name': name,\n",
    "            'function': function,\n",
    "            'kwargs': kwargs\n",
    "        })\n",
    "        return self\n",
    "    \n",
    "    def process(self, input_image):\n",
    "        \"\"\"Execute the full pipeline on an input image.\"\"\"\n",
    "        current_image = input_image.copy()\n",
    "        self.results = {'input': current_image}\n",
    "        \n",
    "        print(\"üõ†Ô∏è Executing Processing Pipeline\")\n",
    "        print(\"=\"*35)\n",
    "        \n",
    "        for i, step in enumerate(self.steps, 1):\n",
    "            print(f\"üìã Step {i}: {step['name']}\")\n",
    "            \n",
    "            try:\n",
    "                current_image = step['function'](current_image, **step['kwargs'])\n",
    "                self.results[step['name']] = current_image\n",
    "                \n",
    "                # Basic statistics\n",
    "                if hasattr(current_image, 'size'):\n",
    "                    size = current_image.size\n",
    "                    mode = current_image.mode\n",
    "                    print(f\"   ‚úÖ Size: {size}, Mode: {mode}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error: {e}\")\n",
    "                break\n",
    "        \n",
    "        return current_image\n",
    "    \n",
    "    def get_results(self):\n",
    "        \"\"\"Return all intermediate results.\"\"\"\n",
    "        return self.results\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"Clear the pipeline steps.\"\"\"\n",
    "        self.steps = []\n",
    "        self.results = {}\n",
    "        return self\n",
    "\n",
    "# Define processing functions compatible with the pipeline\n",
    "def convert_to_grayscale(image):\n",
    "    \"\"\"Convert image to grayscale.\"\"\"\n",
    "    return image.convert('L') if image.mode != 'L' else image\n",
    "\n",
    "def apply_blur(image, radius=3):\n",
    "    \"\"\"Apply Gaussian blur.\"\"\"\n",
    "    return image.filter(ImageFilter.GaussianBlur(radius=radius))\n",
    "\n",
    "def add_border(image, pixels=5, fill_value=0):\n",
    "    \"\"\"Add border around image.\"\"\"\n",
    "    width, height = image.size\n",
    "    new_image = Image.new(image.mode, \n",
    "                         (width + 2 * pixels, height + 2 * pixels), \n",
    "                         fill_value)\n",
    "    new_image.paste(image, (pixels, pixels))\n",
    "    return new_image\n",
    "\n",
    "def apply_contrast(image, factor=1.5):\n",
    "    \"\"\"Adjust image contrast.\"\"\"\n",
    "    from PIL import ImageEnhance\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    return enhancer.enhance(factor)\n",
    "\n",
    "def resize_image(image, size=(128, 128)):\n",
    "    \"\"\"Resize image to target size.\"\"\"\n",
    "    return image.resize(size, Image.Resampling.LANCZOS)\n",
    "\n",
    "# Example pipeline configurations\n",
    "def create_smooth_pipeline():\n",
    "    \"\"\"Pipeline optimized for smooth tactile surfaces.\"\"\"\n",
    "    return (TactileProcessingPipeline()\n",
    "            .add_step(\"Grayscale\", convert_to_grayscale)\n",
    "            .add_step(\"Heavy Blur\", apply_blur, radius=5)\n",
    "            .add_step(\"Border\", add_border, pixels=8)\n",
    "            .add_step(\"Resize\", resize_image, size=(64, 64)))\n",
    "\n",
    "def create_detailed_pipeline():\n",
    "    \"\"\"Pipeline optimized for detailed tactile features.\"\"\"\n",
    "    return (TactileProcessingPipeline()\n",
    "            .add_step(\"Grayscale\", convert_to_grayscale)\n",
    "            .add_step(\"Contrast Boost\", apply_contrast, factor=1.8)\n",
    "            .add_step(\"Light Blur\", apply_blur, radius=1)\n",
    "            .add_step(\"Border\", add_border, pixels=5)\n",
    "            .add_step(\"Resize\", resize_image, size=(128, 128)))\n",
    "\n",
    "def create_artistic_pipeline():\n",
    "    \"\"\"Pipeline for artistic/creative tactile representations.\"\"\"\n",
    "    return (TactileProcessingPipeline()\n",
    "            .add_step(\"Grayscale\", convert_to_grayscale)\n",
    "            .add_step(\"High Contrast\", apply_contrast, factor=2.5)\n",
    "            .add_step(\"Medium Blur\", apply_blur, radius=3)\n",
    "            .add_step(\"Large Border\", add_border, pixels=12)\n",
    "            .add_step(\"Resize\", resize_image, size=(96, 96)))\n",
    "\n",
    "# Test the pipelines\n",
    "print(\"üõ†Ô∏è Custom Processing Pipeline Framework\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "pipelines = {\n",
    "    \"Smooth\": create_smooth_pipeline(),\n",
    "    \"Detailed\": create_detailed_pipeline(),\n",
    "    \"Artistic\": create_artistic_pipeline()\n",
    "}\n",
    "\n",
    "pipeline_results = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    print(f\"\\nüéØ Testing {name} Pipeline:\")\n",
    "    result = pipeline.process(demo_img)\n",
    "    pipeline_results[name] = result\n",
    "    print(f\"   Final result: {result.size}, {result.mode}\")\n",
    "\n",
    "print(\"\\nüí° Pipeline Usage Tips:\")\n",
    "print(\"‚Ä¢ Smooth: For accessibility and comfort\")\n",
    "print(\"‚Ä¢ Detailed: For educational or technical models\")\n",
    "print(\"‚Ä¢ Artistic: For creative and expressive pieces\")\n",
    "print(\"‚Ä¢ Custom: Build your own for specific requirements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Hands-On Exercise: Parameter Optimization\n",
    "\n",
    "Your turn to experiment with different processing parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Exercise: Parameter Optimization\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "exercise_challenges = [\n",
    "    {\n",
    "        \"challenge\": \"Tactile Comfort Optimization\",\n",
    "        \"goal\": \"Create the smoothest possible tactile surface\",\n",
    "        \"constraints\": [\"Must preserve main features\", \"Eliminate sharp edges\"],\n",
    "        \"suggested_params\": \"Try gaussian_blur_radius 3-8, moderate clamping\",\n",
    "        \"success_criteria\": \"Smooth gradients, no sudden height changes\"\n",
    "    },\n",
    "    {\n",
    "        \"challenge\": \"Maximum Detail Preservation\",\n",
    "        \"goal\": \"Retain as much detail as possible while ensuring printability\",\n",
    "        \"constraints\": [\"Minimal blur\", \"High contrast\", \"Sharp features\"],\n",
    "        \"suggested_params\": \"Try gaussian_blur_radius 0-2, wide clamping range\",\n",
    "        \"success_criteria\": \"Fine details visible, crisp boundaries\"\n",
    "    },\n",
    "    {\n",
    "        \"challenge\": \"Accessibility Optimization\",\n",
    "        \"goal\": \"Optimize for visually impaired users\",\n",
    "        \"constraints\": [\"Clear tactile differences\", \"Intuitive height mapping\"],\n",
    "        \"suggested_params\": \"Try strategic clamping, test both inversion modes\",\n",
    "        \"success_criteria\": \"Distinct tactile regions, logical depth\"\n",
    "    },\n",
    "    {\n",
    "        \"challenge\": \"3D Printing Optimization\",\n",
    "        \"goal\": \"Ensure successful 3D printing\",\n",
    "        \"constraints\": [\"Stable base\", \"No overhangs\", \"Reasonable size\"],\n",
    "        \"suggested_params\": \"Try larger borders, moderate heights\",\n",
    "        \"success_criteria\": \"Printable geometry, stable structure\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, challenge in enumerate(exercise_challenges, 1):\n",
    "    print(f\"\\nüèÜ Challenge {i}: {challenge['challenge']}\")\n",
    "    print(f\"   üéØ Goal: {challenge['goal']}\")\n",
    "    print(f\"   ‚ö†Ô∏è  Constraints: {', '.join(challenge['constraints'])}\")\n",
    "    print(f\"   üí° Suggested: {challenge['suggested_params']}\")\n",
    "    print(f\"   ‚úÖ Success: {challenge['success_criteria']}\")\n",
    "\n",
    "print(\"\\nüìã Exercise Template:\")\n",
    "template_code = '''\n",
    "# Create your test image\n",
    "test_img = create_demo_depth_map(size=(256, 256))\n",
    "\n",
    "# Test different parameter combinations\n",
    "from art_tactile_transform.main import process_image\n",
    "\n",
    "# Example: Smooth surface optimization\n",
    "smooth_result = process_image(\n",
    "    test_img.convert('L'),\n",
    "    gaussian_blur_radius=5,\n",
    "    clamp_min=50,\n",
    "    clamp_max=200,\n",
    "    border_pixels=10,\n",
    "    invert_heights=False\n",
    ")\n",
    "\n",
    "# Analyze your results\n",
    "img_array = np.array(smooth_result)\n",
    "print(f\"Height range: {img_array.min():.1f} - {img_array.max():.1f}\")\n",
    "print(f\"Standard deviation: {img_array.std():.1f}\")\n",
    "'''\n",
    "print(template_code)\n",
    "\n",
    "print(\"\\nüìä Evaluation Metrics:\")\n",
    "metrics = [\n",
    "    \"Visual inspection of processed image\",\n",
    "    \"Height range and distribution analysis\",\n",
    "    \"Edge sharpness measurement\",\n",
    "    \"Surface smoothness assessment\",\n",
    "    \"Final STL file quality check\"\n",
    "]\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"‚Ä¢ {metric}\")\n",
    "\n",
    "print(\"\\nüé≤ Bonus Challenge:\")\n",
    "print(\"Create a custom processing function that automatically\")\n",
    "print(\"optimizes parameters based on image content analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Troubleshooting Common Issues\n",
    "\n",
    "Let's address common image processing problems and their solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß Troubleshooting Image Processing Issues\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "common_issues = {\n",
    "    \"Low Contrast Output\": {\n",
    "        \"symptoms\": [\"Flat-looking result\", \"Poor tactile variation\", \"Minimal height differences\"],\n",
    "        \"causes\": [\"Narrow clamping range\", \"Over-blurring\", \"Poor source depth map\"],\n",
    "        \"solutions\": [\"Widen clamp_min/max range\", \"Reduce blur radius\", \"Try different AI model\"]\n",
    "    },\n",
    "    \"Too Noisy/Rough\": {\n",
    "        \"symptoms\": [\"Sharp jagged edges\", \"Uncomfortable tactile feel\", \"Printing artifacts\"],\n",
    "        \"causes\": [\"No blur applied\", \"High-frequency noise in depth map\", \"Inappropriate clamping\"],\n",
    "        \"solutions\": [\"Increase blur radius\", \"Apply histogram equalization\", \"Use edge-preserving filter\"]\n",
    "    },\n",
    "    \"Lost Detail\": {\n",
    "        \"symptoms\": [\"Important features disappeared\", \"Over-smoothed result\", \"Blob-like appearance\"],\n",
    "        \"causes\": [\"Excessive blur\", \"Over-aggressive clamping\", \"Too low resolution\"],\n",
    "        \"solutions\": [\"Reduce blur radius\", \"Adjust clamp range\", \"Increase target resolution\"]\n",
    "    },\n",
    "    \"Inverted Depth\": {\n",
    "        \"symptoms\": [\"Foreground appears sunken\", \"Background raised\", \"Counterintuitive tactile feel\"],\n",
    "        \"causes\": [\"Wrong invert_heights setting\", \"Depth model interpretation\", \"Lighting confusion\"],\n",
    "        \"solutions\": [\"Toggle invert_heights\", \"Try different AI model\", \"Manually invert image\"]\n",
    "    },\n",
    "    \"Size Issues\": {\n",
    "        \"symptoms\": [\"Model too large/small\", \"Printing time excessive\", \"Detail loss on resize\"],\n",
    "        \"causes\": [\"Border pixels too large\", \"Inappropriate resolution\", \"Poor resize algorithm\"],\n",
    "        \"solutions\": [\"Adjust border_pixels\", \"Change target resolution\", \"Use better resampling\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "for issue, details in common_issues.items():\n",
    "    print(f\"\\n‚ùå {issue}\")\n",
    "    print(f\"   üîç Symptoms: {', '.join(details['symptoms'])}\")\n",
    "    print(f\"   üß† Causes: {', '.join(details['causes'])}\")\n",
    "    print(f\"   üîß Solutions: {', '.join(details['solutions'])}\")\n",
    "\n",
    "print(\"\\nüéØ Debugging Workflow:\")\n",
    "debug_steps = [\n",
    "    \"1. Check original depth map quality\",\n",
    "    \"2. Test with minimal processing (no blur, no clamping)\",\n",
    "    \"3. Add processing steps one by one\",\n",
    "    \"4. Compare with known good results\",\n",
    "    \"5. Visualize intermediate steps\",\n",
    "    \"6. Test with different source images\"\n",
    "]\n",
    "\n",
    "for step in debug_steps:\n",
    "    print(step)\n",
    "\n",
    "print(\"\\nüõ°Ô∏è Prevention Tips:\")\n",
    "prevention_tips = [\n",
    "    \"Start with conservative parameters\",\n",
    "    \"Always visualize intermediate results\",\n",
    "    \"Keep notes on parameter combinations\",\n",
    "    \"Test with diverse image types\",\n",
    "    \"Validate on actual 3D prints when possible\"\n",
    "]\n",
    "\n",
    "for tip in prevention_tips:\n",
    "    print(f\"‚Ä¢ {tip}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Key Concepts Summary\n",
    "\n",
    "After completing this notebook, you should understand:\n",
    "\n",
    "### ‚úÖ Image Processing Pipeline\n",
    "- **Processing Stages**: Grayscale conversion, blurring, clamping, normalization\n",
    "- **Parameter Effects**: How each setting affects the final tactile result\n",
    "- **Trade-offs**: Balancing smoothness, detail, and printability\n",
    "- **Tactile Considerations**: Optimizing for human touch perception\n",
    "\n",
    "### ‚úÖ Advanced Techniques\n",
    "- **Histogram Equalization**: Improving contrast distribution\n",
    "- **Adaptive Processing**: Variable processing based on image content\n",
    "- **Edge Preservation**: Maintaining boundaries while smoothing\n",
    "- **Multi-scale Processing**: Combining different detail levels\n",
    "\n",
    "### ‚úÖ Practical Skills\n",
    "- **Parameter Tuning**: Systematic optimization approaches\n",
    "- **Custom Pipelines**: Building flexible processing workflows\n",
    "- **Troubleshooting**: Identifying and solving common issues\n",
    "- **Quality Assessment**: Evaluating processing results\n",
    "\n",
    "## üéØ Next Steps\n",
    "\n",
    "Continue your learning journey with:\n",
    "\n",
    "- **04_3d_modeling_stl_generation.ipynb** - Learn how processed images become 3D models\n",
    "- **05_hands_on_exercises.ipynb** - Practice with comprehensive coding challenges\n",
    "- **06_advanced_challenges.ipynb** - Tackle complex enhancement projects\n",
    "\n",
    "## üî¨ Challenge Questions\n",
    "\n",
    "Test your understanding:\n",
    "\n",
    "1. **How would you optimize processing for a photograph vs. a line drawing?**\n",
    "2. **What processing approach would work best for creating braille-like tactile patterns?**\n",
    "3. **How might you automatically detect optimal blur radius for a given image?**\n",
    "4. **What considerations are important when processing images for children vs. adults?**\n",
    "5. **How would you modify the pipeline for different 3D printer capabilities?**\n",
    "\n",
    "---\n",
    "*Ready to explore 3D modeling and STL generation? Let's dive deeper! üöÄ*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}